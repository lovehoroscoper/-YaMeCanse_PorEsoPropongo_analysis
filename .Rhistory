text <- tm_map(text, removeWords, stopwords("es-419"))
text <- tm_map(text, removeWords, stopwords(kind = "es-419"))
text <- tm_map(text, removeWords, stopwords(kind = "SMART"))
install.packages("SnowballC")
text <- tm_map(text, removeWords, stopwords(kind = "SMART"))
library(SnowballC)
text <- tm_map(text, removeWords, stopwords(kind = "SMART"))
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "es-419"))
inspect(text[1:3])
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
text <- tm_map(text, removeWords, stopwords(kind = "SMART"))
text <- tm_map(text, removeWords, stopwords(kind = "SMART"), mc.cores=1)
wordcloud(text, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, “Dark2″))
wordcloud(text, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
library(wordcloud)
wordcloud(text, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "es-419"))
inspect(text[1:3])
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
wordcloud(text, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(text, scale=c(5,0.5), max.words=10, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
inspect(text[1:3])
text <- tm_map(text, stemDocument)
findFreqTerms(text, 2, 3)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "es-419"))
inspect(text[1:3])
words = c("yamecanse", "por", "eso", "propongo", "que")
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
stopwords("en")
stopwords("spanish")
View(data)
text <- tm_map(text, removeWords)
text <- tm_map(text, removeWords, mc.cores=1)
text <- tm_map(text, removeWords, c("yamecanse", "poresopropongo", "por", "eso", "propongo", "que"), mc.cores=1)
words <- stopwords("spanish")
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
inspect(text[1:3])
text <- tm_map(text, stemDocument, language = "spanish")
inspect(text[1:3])
stopwords("spanish")
text <- tm_map(text, removeWords, stopwords("spanish")
)
text <- tm_map(text, removeWords, stopwords("spanish"), mc.cores=1)
words = c(stopwords("spanish"), "yamecanse", "poresopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, removeWords, words, mc.cores=1)
text <- tm_map(text, removeWords(words), mc.cores=1)
text <- tm_map(text, removeWords(text, words), mc.cores=1)
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
# add useless words to stopwords
words = c(stopwords("spanish"), "yamecanse", "poresopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
text <- tm_map(text, stemDocument, language = "spanish")
text <- tm_map(text, removeWords, words, mc.cores=1)
words
text <- tm_map(text, removeWords, stopwords("english"), mc.cores=1)
text <- tm_map(text, removeWords, stopwords("english"))
text <- tm_map(text, removeWords, stopwords("english"), mc.cores=1)
text <- tm_map(text, removeWords, stopwords("english"), lazy=TRUE, mc.cores=1)
text <- tm_map(text, removeWords, words, lazy=TRUE, mc.cores=1)
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
words = c(stopwords("spanish"), "yamecanse", "poresopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
inspect(text[1:3])
text <- tm_map(text, removeWords, words, lazy=TRUE, mc.cores=1)
inspect(text[1:3])
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
# add useless words to stopwords
words = c(stopwords("spanish"), "yamecanse", "poresopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, stripWhitespace, mc.cores=1)
inspect(text[1:3])
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
inspect(text[1:3])
text <- tm_map(text, removeNumbers)
inspect(text[1:3])
text <- tm_map(text, removePunctuation)
inspect(text[1:3])
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text[1:3])
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
text <- tm_map(text, stripWhitespace, mc.cores=1)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
inspect(text[1:3])
text <- tm_map(text, removeWords, stopwords("spanish"), lazy=TRUE)
inspect(text[1:3])
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
inspect(text[1:3])
text <- tm_map(text, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1)
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
inspect(text[1:3])
text <- tm_map(text, removeWords, stopwords("spanish"), lazy=TRUE)
inspect(text[1:3])
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text[1:3])
words = c(stopwords("spanish"), "yamecanse", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "por", "eso", "propongo", "que")
words = c(stopwords("spanish"), "yamecanse", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1)   # MUST convert data to avoid errors
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text[1:3])
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:3])
# add needed words to stopwords
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1)   # MUST convert data to avoid errors
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removePunctuation)
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text[1:3])
inspect(text[1:10])
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
text <- tm_map(text, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1)   # MUST convert data to avoid errors
inspect(text[1:10])
text <- tm_map(text, content_transformer(tolower))
inspect(text[1:10])
text <- tm_map(text, removePunctuation)
inspect(text[1:10])
text <- tm_map(text, removeNumbers)
inspect(text[1:10])
text <- tm_map(text, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub="")),
mc.cores=1)   # MUST convert data to avoid errors
inspect(text[1:10])
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub="")),
mc.cores=1)   # MUST convert data to avoid errors
inspect(text[1:10])
text <- tm_map(text, content_transformer(function(x) iconv(x, to="ASCII", sub="")),
mc.cores=1)   # MUST convert data to avoid errors
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
text <- tm_map(text, content_transformer(function(x) iconv(x, to="ASCII", sub="")),
mc.cores=1)   # MUST convert data to avoid errors
inspect(text[1:10])
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
encoding(x)
Encoding(x)
Encoding(text)
x <- "fa\xE7ile"
Encoding(x)
x <- c("fa\xE7ile", "fa\xE7ile")
Encoding(x)
Encoding(words)
words[1:10]
words[1:30]
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-8" to="ASCII", sub="")),
mc.cores=1)   # MUST convert data to avoid errors
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-8", to="ASCII", sub="")),
mc.cores=1)   # MUST convert data to avoid errors
inspect(text[1:10])
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "UTF-8-MAC", sub="")),
mc.cores=1)   # MUST convert data to avoid errors
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text[1:10])
wordcloud(text, scale=c(5,0.5), max.words=10, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(text, scale=c(5,0.5), max.words=50, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
proposals <- data$Body[1]
proposals
proposals <- data$Body[5]
proposals
x <- #YaMeCans\x8e
x <- YaMeCans\x8e
x <- "YaMeCans\x8e"
x
Encoding(x)
Encoding(x) <- "latin1"
Encoding(x)
x
text <- tm_map(text, content_transformer(function(x) iconv(x, from="latin1" to = "UTF-8-MAC", sub="")),
mc.cores=1)   # MUST convert data to avoid errors
text <- tm_map(text, content_transformer(function(x) iconv(x, from="latin1", to = "UTF-8-MAC", sub="")), mc.cores=1)   # MUST convert data to avoid errors
proposals <- data$Body[5]
#proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
text <- tm_map(text, content_transformer(function(x) iconv(x, from="latin1",
to = "UTF-8-MAC", sub="")), mc.cores=1)   #
text
inspect(text[1:10])
proposals <- data$Body[5]
#proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
# add needed words to stopwords
#words = c(stopwords("spanish"), "#", "yamecanse", "yamecansepor", "poresopropongo",
#          "yamecanseporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, content_transformer(function(x) iconv(x,
to = "latin1", sub="")), mc.cores=1)   #
inspect(text[1:10])
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
#inspect(text[1:10])
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x,
to = "latin1"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x,
to = "latin1")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
#inspect(text[1:10])
inspect(text)
Encoding(text)
Encoding(text) <- "latin1"
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "latin1")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "latin1", sub = "byte")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "UTF-8", sub = "byte")))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "UTF-8", sub = "?")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "UTF-8", sub = "?")))
inspect(text)
incovlist()
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from ="latin1", to = "UTF-8", sub = "?")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "latin1", sub = "?")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "latin1", sub = "")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, to = "ASCII", sub = "")))
inspect(text)
iconv(5)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-8", to = "latin1", sub = "")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-8", to = "ASCII", sub = "")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-8", to = "ASCII", sub = "byte")))
inspect(text)
x <- "#YaMeCans<8e>"
Encoding(x)
Encoding(x) <- "UTF-8"
x
x <- "#YaMeCans<8e>"
Encoding(x)
Encoding(x) <- "latin1"
x
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "latin1"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "latin1"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA"))
library(foreign)
library(data.table)
library(SnowballC)
library(tm)
library(wordcloud)
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "latin1"))
names(data)                                 # verifies all variables are loaded properly
length(data$ID)                             # verifies that no observations were lost
data[, unique.id:=.GRP, by=data$Customer]
View(data)
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "UTF-8"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "UTF-8"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "latin1"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "UTF-8"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted.txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "utf8"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted (utf16).txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "utf16"))
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted (utf16).txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "UTF-16"))
names(data)                                 # verifies all variables are loaded properly
length(data$ID)                             # verifies that no observations were lost
data[, unique.id:=.GRP, by=data$Customer]   # creates unique user identifier
View(data)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-16", to = "ASCII", sub = "byte")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-16", to = "UTF-8-MAC", sub = "byte")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-16", to = "latin1", sub = "byte")))
inspect(text)
View(data)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-16", to = "ASCII//TRANSLIT", sub = "byte")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-16", to = "UTF-8", sub = "byte")))
inspect(text)
unwanted_array = list(    'Š'='S', 'š'='s', 'Ž'='Z', 'ž'='z', 'À'='A', 'Á'='A', 'Â'='A', 'Ã'='A', 'Ä'='A', 'Å'='A', 'Æ'='A', 'Ç'='C', 'È'='E', 'É'='E',
'Ê'='E', 'Ë'='E', 'Ì'='I', 'Í'='I', 'Î'='I', 'Ï'='I', 'Ñ'='N', 'Ò'='O', 'Ó'='O', 'Ô'='O', 'Õ'='O', 'Ö'='O', 'Ø'='O', 'Ù'='U',
'Ú'='U', 'Û'='U', 'Ü'='U', 'Ý'='Y', 'Þ'='B', 'ß'='Ss', 'à'='a', 'á'='a', 'â'='a', 'ã'='a', 'ä'='a', 'å'='a', 'æ'='a', 'ç'='c',
'è'='e', 'é'='e', 'ê'='e', 'ë'='e', 'ì'='i', 'í'='i', 'î'='i', 'ï'='i', 'ð'='o', 'ñ'='n', 'ò'='o', 'ó'='o', 'ô'='o', 'õ'='o',
'ö'='o', 'ø'='o', 'ù'='u', 'ú'='u', 'û'='u', 'ý'='y', 'ý'='y', 'þ'='b', 'ÿ'='y' )
unwanted_array_list
unwanted_array
unwanted_array = list(    'Š'='S', 'š'='s', 'Ž'='Z', 'ž'='z',
'À'='A', 'Á'='A', 'Â'='A', 'Ã'='A', 'Ä'='A', 'Å'='A', 'Æ'='A',
'Ç'='C', 'È'='E', 'É'='E', 'Ê'='E', 'Ë'='E',
'Ì'='I', 'Í'='I', 'Î'='I', 'Ï'='I',
'Ñ'='N', 'Ò'='O', 'Ó'='O', 'Ô'='O', 'Õ'='O', 'Ö'='O', 'Ø'='O',
'Ù'='U', 'Ú'='U', 'Û'='U', 'Ü'='U', 'Ý'='Y', 'Þ'='B', 'ß'='Ss',
'à'='a', 'á'='a', 'â'='a', 'ã'='a', 'ä'='a', 'å'='a', 'æ'='a', 'ç'='c',
'è'='e', 'é'='e', 'ê'='e', 'ë'='e', 'ì'='i', 'í'='i', 'î'='i', 'ï'='i',
'ð'='o', 'ñ'='n', 'ò'='o', 'ó'='o', 'ô'='o', 'õ'='o',
'ö'='o', 'ø'='o', 'ù'='u', 'ú'='u', 'û'='u', 'ý'='y', 'ý'='y',
'þ'='b', 'ÿ'='y' )
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- tm_map(text, content_transformer(function(x) iconv(x, from="UTF-16", to = "UTF-8", sub = "byte")))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
library(gsubfn)
packages.install("gsubfn")
install.packages("gsubfn")
library(gsubfn)
library(gsubfn)
string="Hølmer"
gsubfn(paste(names(unwanted_array),collapse='|'), unwanted_array,string)
gsubfn(paste(names(unwanted_array),collapse='|'), unwanted_array,text)
string="Hølmer is Hølmer"
gsubfn(paste(names(unwanted_array),collapse='|'), unwanted_array,string)
data <- as.data.table(read.delim("Postcard Dashboard  Orders - Movement Postcards_converted (utf16).txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "UTF-16"))
names(data)                                 # verifies all variables are loaded properly
length(data$ID)                             # verifies that no observations were lost
data[, unique.id:=.GRP, by=data$Customer]
View(data)
data$Body[1]
data$Body[6]
proposals <- data$Body[6]
proposals
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
text <- tm_map(text, removeNumbers)
text <- tm_map(text, removePunctuation)
text <- tm_map(text, removeWords, words, lazy=TRUE)
text
proposals <- data$Body[6]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
inspect(text)
text <- tm_map(text, removeNumbers)
inspect(text)
text <- tm_map(text, removePunctuation)
inspect(text)
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text)
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansé" "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "yamecanséporesopropongo" "por", "eso", "propongo", "que")
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansé" "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "yamecanséporesopropongo", "por", "eso", "propongo", "que")
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansé", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "yamecanséporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text)
proposals <- data$Body[!is.na(data$Body)]
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text[1:10])
text <- VCorpus(VectorSource(proposals), readerControl= list(language = "spanish"))
inspect(text)
words = c(stopwords("spanish"), "#", "yamecanse", "yamecansé", "yamecansepor", "poresopropongo",
"yamecanseporesopropongo", "yamecanséporesopropongo", "por", "eso", "propongo", "que")
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower), mc.cores=1)
inspect(text[1:10])
text <- tm_map(text, removeNumbers)
inspect(text[1:10])
text <- tm_map(text, removePunctuation)
inspect(text[1:10])
text <- tm_map(text, removeWords, words, lazy=TRUE)
inspect(text[1:10])
text <- tm_map(text, stripWhitespace)
inspect(text[1:10])
wordcloud(text, scale=c(5,0.5), max.words=50, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
frequencies <- TermDocumentMatrix(text)
frequencies
summary(frequencies)
inspect[frequencies[1:10]]
inspect(frequencies[1:10])
inspect(frequencies)
findFreqTerms(frequencies)
findFreqTerms(frequencies, 100)
inspect(frequencies)
mat <- rowSums(as.matrix(frequencies))
names(mat) <- rownames(as.matrix(frequencies))
mat <- sort(mat, decreasing=T)
mat[1:200]
mat <- as.data.frame(mat)
View(mat)
write.csv(mat, file="word_frequencies.csv")
setwd("~/Documents/#YaMeCanse_postales")
getwd()
data <- as.data.table(read.delim(
"data/Postcard Dashboard  Orders - Movement Postcards_converted (utf16).txt",
header=TRUE, sep="\t", na.strings = "NA", fileEncoding = "UTF-16"))
pdf("graphs/wordcloud_example.pdf", width=1280,height=800)
wordcloud(text, scale=c(5,0.5), max.words=50, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
dev.off()
pdf("graphs/wordcloud_example.pdf", width=1280,height=800)
wordcloud(text, scale=c(5,0.5), max.words=50, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
dev.off()
wordcloud(text, scale=c(5,0.5), max.words=50, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
rm(list=ls(all=TRUE))
